# -*- coding: utf-8 -*-
"""Transfer_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/196PzpvsG8a0htV2ZP_v8068dl1HB1mMs

**PNEUMONIA CLASSIFIER**
"""

from google.colab import drive
drive.mount('/content/drive')

import os, math, json
import numpy as np
from matplotlib import pyplot as plt
import matplotlib.image as mpimg
import shutil
import urllib.request
import seaborn as sns
import tensorflow as tf
import random
tf.enable_eager_execution()
AUTO = tf.data.experimental.AUTOTUNE

# Load and set training, testing, and validation variables.
!wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/41d542e7-7f91-47f6-9ff2-dd8e5a5a7861/ChestXRay2017.zip

from zipfile import ZipFile
with ZipFile("./ChestXRay2017.zip", "r") as f:
    f.extractall(path = "./")

train_files = "./chest_xray/train/"
test_files = "./chest_xray/test/"
categories = ['NORMAL', 'PNEUMONIA']

# Import Tensorflow and Keras
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.utils.class_weight import compute_class_weight

# Build the model using Inception v3
NUM_CLASSES = 2 

def create_model(input_shape, num_classes):
  
  K.clear_session()
  # Use Inception v3 as the leveraged model
  inceptionv3_model = InceptionV3(weights='imagenet', include_top= False, input_shape=input_shape)
  
  #Add custom layers on top 
  
  x = inceptionv3_model.output
  x = GlobalAveragePooling2D(name='avg_pool')(x)
  x = Dense(512, activation='relu')(x)
  x = Dropout(0.3)(x)
  x = Dense(256, activation='relu')(x)
  x = Dropout(0.3)(x)
  x = Dense(128, activation='relu')(x)
  x = Dropout(0.3)(x)
  
  #Make sure layer weights of the inceptionv3 model is constant
  for layer in inceptionv3_model.layers:
    layer.trainable = False
    
  #Using sigmoid activations to classify dataset via num_classes
  predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)
  
  #Instantiate the new model
  model = Model(inputs=inceptionv3_model.inputs, outputs=predictions)
  
  return model

#Training loss
training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)

#Training Accuracy
training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy', dtype=tf.float32)

#Test loss
test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)

#Test Accuracy
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy', dtype=tf.float32)

#Create Model and Model Summary
model = create_model((150, 150, 3), NUM_CLASSES)
model.summary()

#Use the Adam Optimizer 
optimizer = Adam(lr=0.0001)

#Compile
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

#Feature Engineering
# return the numbers of files in a directory
def dir_file_count(directory):
  return sum([len(files) for r, d, files in os.walk(directory)])

#Create batch iterators for the train, validation, and testing data
#Configuration parameters
rescale = 1./255
target_size = (150,150)
batch_size = 256
class_mode = 'categorical'

#Augment the training dataset images
train_datagen = ImageDataGenerator(rescale=rescale, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)

#Load the training images in the generator
train_generator = train_datagen.flow_from_directory(train_files, target_size=target_size, class_mode=class_mode,
                                                    batch_size=batch_size, shuffle =True)

#Augment the validation dataset images

#Load the validation images in the generator
val_iterator = train_datagen.flow_from_directory(train_files, 
                                                          target_size = target_size, 
                                                          batch_size = 256, 
                                                          shuffle = False, 
                                                          class_mode = class_mode,
                                                          subset = "validation")

#Augment the test dataset images
test_datagen = ImageDataGenerator(rescale=rescale)

#Load the testing images in the generator

test_generator = test_datagen.flow_from_directory(test_files, target_size=target_size,
                                                 class_mode=class_mode, batch_size=dir_file_count(test_files),
                                                  shuffle=False)

#Define the category label weights since the training data is unbalanced
y = train_generator.classes
labels = np.unique(y)

train_class_weights = compute_class_weight('balanced', labels, y)
print(train_class_weights)

#Train the model
history = model.fit_generator(train_generator, steps_per_epoch = len(train_generator),
                                epochs=10, verbose=1, workers=20, validation_data = val_iterator,
                                validation_steps=len(val_iterator),
                                class_weight = train_class_weights)

#Save the model after Training
MODEL_FILE = 'pneumonia.hd5'
model.save(MODEL_FILE)

#Evaluate the Model
#Load and Run the model on test data
model = tf.keras.models.load_model(MODEL_FILE)
eval_result = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)

print("%s%.2f%s"% ("Accuracy : ", eval_result[1]*100, "%"))
print("%s%.2f"% ("Loss : ", eval_result[0]))

#Prediction using the Model
y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)
y_pred = y_pred.argmax(axis=-1)
y_true = test_generator.classes

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report

#Create confusion matrix
con_matrix = confusion_matrix(y_true, y_pred)
print(con_matrix)

#Classification Report
target_names = ["PNEUMONIA", "NORMAL"]
cls_report_print = classification_report(y_true, y_pred, target_names = target_names )
print(cls_report_print)

#Visualization of the predictions of a random test dataset batch
from random import randint
import cv2

label_d = ["PNEUMONIA", "NORMAL"]

test_file_names = test_generator.filenames
n = len(test_file_names)

plt.rcParams["figure.figsize"] = [32, 20] 

for i in range(10):
    index = randint(0, n - 1)
    file_name = test_files + test_file_names[index]
    
    image = cv2.imread(file_name, cv2.IMREAD_COLOR)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    actual_label = label_d[int(test_generator.classes[index])]
    pred_label = label_d[int(y_pred[index])]
    
    plt.subplot(10, 1, i + 1)
    plt.axis("off")
    plt.imshow(image)
    
    title = "Actual = " + actual_label + " Prediction = " + pred_label
    plt.title(title)

plt.tight_layout()
plt.show()

